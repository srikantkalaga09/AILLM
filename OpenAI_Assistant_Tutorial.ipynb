{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+Z5tn3trqHTm7LSDJHSVS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PradipNichite/Youtube-Tutorials/blob/main/OpenAI_Assistant_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "G9k10WZJI41t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6739de0-5e5c-4ced-cc25-08391425bf8b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.2.3)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key=\"key\")\n",
        "client"
      ],
      "metadata": {
        "id": "HA7glsvHJdop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d12fafe-ac7d-4031-8303-ee4e86de1877"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<openai.OpenAI at 0x7d8d29c0ccd0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Upload File"
      ],
      "metadata": {
        "id": "jSO3_datOyJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_file = client.files.create(\n",
        "    file=open(\"/content/FutureSmart AI_ Custom Natural Language Processing Solutions _ NLP _ GPT-3 _ ChatGPT _ Semantic Search..html\", 'rb'),\n",
        "    purpose='assistants',\n",
        ")"
      ],
      "metadata": {
        "id": "DE6f7qaZKWZW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnHtMZI7aw8B",
        "outputId": "bf884348-26c5-4d42-8f8e-e10993596f34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-EWKqY7PCZ6KMDjnLV6hR6pcP', bytes=464362, created_at=1699689980, filename='FutureSmart AI_ Custom Natural Language Processing Solutions _ NLP _ GPT-3 _ ChatGPT _ Semantic Search..html', object='file', purpose='assistants', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Assistant"
      ],
      "metadata": {
        "id": "-gFb8p-MO6Cm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c9CpYWwGIxMK"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=\"Futuresmart AI Assistent\",\n",
        "    instructions=\"You are a AI Assistent that answers any queries related to Futuresmart AI\",\n",
        "    tools=[{\"type\": \"retrieval\"}],\n",
        "    model=\"gpt-4-1106-preview\",\n",
        "    file_ids=[uploaded_file.id]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Thread"
      ],
      "metadata": {
        "id": "h91zPAXAO-yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread = client.beta.threads.create()"
      ],
      "metadata": {
        "id": "aFBhcp8AI6tW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thread"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTkVBF44b33K",
        "outputId": "25ec0c12-125e-4386-aa13-3efb596cd3d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Thread(id='thread_B9IWzBfHFD2AQaCNf0cd3pmh', created_at=1699690277, metadata={}, object='thread')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what is Futuresmart AI?\n",
        "# What services does it offer?\n",
        "# What tech stack does Futuresmart AI use?\n",
        "# What clients says about Futuresmart AI?"
      ],
      "metadata": {
        "id": "ihK8N3hSM70W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Message Inside Thread"
      ],
      "metadata": {
        "id": "wM0X1ZRUPEcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"What clients says about Futuresmart AI?\"\n",
        ")"
      ],
      "metadata": {
        "id": "aQCeqHU3LLyi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.beta.threads.messages.list(thread_id=thread.id).data\n",
        "# client.beta.threads.messages.list(thread_id=thread.id).data[0].content[0].text.value"
      ],
      "metadata": {
        "id": "cctlqZDBMLwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d35b35-b7d1-4c5f-cf64-50400d607a51"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ThreadMessage(id='msg_ewzcNNhodLaLLirBC7nmmgjN', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What services does it offer?'), type='text')], created_at=1699690636, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_B9IWzBfHFD2AQaCNf0cd3pmh'),\n",
              " ThreadMessage(id='msg_1jMoPyojABVNYWoUtagDH8mK', assistant_id='asst_qaBEk8siaY1mdOcrHAOj8UpB', content=[MessageContentText(text=Text(annotations=[TextAnnotationFileCitation(end_index=324, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-EWKqY7PCZ6KMDjnLV6hR6pcP', quote='FutureSmart AI provides custom Natural Language Processing (NLP) solutions for companies looking to get ahead of the future.\\\\nOur dedicated team of Data Scientists and ML Engineers provides an end-to-end solution from data labeling to modeling and deploying an ML model tailored to your specific use case'), start_index=314, text='【9†source】', type='file_citation')], value=\"FutureSmart AI is a company that provides custom Natural Language Processing (NLP) solutions tailored for companies seeking to advance their capabilities with AI. They offer an end-to-end solution encompassing data labeling, modeling, and deploying machine learning models specific to clients' individual use cases【9†source】.\"), type='text')], created_at=1699690436, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_HJLeqkxODRz5aIaXBhwSsiTz', thread_id='thread_B9IWzBfHFD2AQaCNf0cd3pmh'),\n",
              " ThreadMessage(id='msg_hhqFIj7r6zC6CP91TKaq2geT', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='what is Futuresmart AI?'), type='text')], created_at=1699690354, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_B9IWzBfHFD2AQaCNf0cd3pmh')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run Assistent"
      ],
      "metadata": {
        "id": "UuVSLBSJPJpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id\n",
        ")\n",
        "# run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "# run"
      ],
      "metadata": {
        "id": "wEpXo8P8LTJR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Retrive Assistant's Response"
      ],
      "metadata": {
        "id": "uij6eRS9PXc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "    if run.status==\"completed\":\n",
        "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "        latest_message = messages.data[0]\n",
        "        text = latest_message.content[0].text.value\n",
        "        print(text)\n",
        "        break;"
      ],
      "metadata": {
        "id": "WbQuRT7QLb7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95430336-6bcb-4358-84bb-bee36354b0b8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clients have provided positive testimonials about their experiences with FutureSmart AI:\n",
            "\n",
            "1. One client praised the engineer as very hardworking and talented, with high integrity in their work and transparency in work progress. They highly recommended them for work related to Natural Language Processing (NLP) in the AI space【32†source】.\n",
            "\n",
            "2. Another client highlighted the expertise in NLP and MLOps and appreciated that the engineer not only completed the job but also proposed best practices and further approaches that added value to the final product. They remarked on the smooth communication and quick comprehension skills, expressing that the collaboration would continue for a long time【33†source】.\n",
            "\n",
            "3. The same sentiments were echoed by a client named Binoocle from Upwork, indicating a strong ongoing partnership【34†source】.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ohya4cwNfBu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}