{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHyxJehM9c+9QdAYG89ISv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PradipNichite/Youtube-Tutorials/blob/main/OpenAI_Speech_to_Text_and_Text_to_Speech_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1m7L5H3lM-4A"
      },
      "outputs": [],
      "source": [
        "!pip install openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"sk-\""
      ],
      "metadata": {
        "id": "heUAiWAbNCTC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key = api_key)"
      ],
      "metadata": {
        "id": "h7AQWQxkNnaq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text to speech\n",
        "\n",
        "https://platform.openai.com/docs/guides/text-to-speech/text-to-speech\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lkbaW0-gRStT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speech_file_path = \"steve_jobs_speech_generated_hd.mp3\"\n",
        "response = client.audio.speech.create(\n",
        "  # model=\"tts-1\",\n",
        "  model=\"tts-1-hd\",\n",
        "  # voice=\"alloy\",\n",
        "  voice = \"echo\",\n",
        "  # voice = \"fable\",\n",
        "  # voice = \"onyx\",\n",
        "  # voice = \"nova\",\n",
        "  # voice = \"shimmer\",\n",
        "  input=\"Your time is limited, so don’t waste it living someone else’s life. Don’t be trapped by dogma — which is living with the results of other people’s thinking. Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary...Stay Hungry. Stay Foolish.\"\n",
        ")\n",
        "\n",
        "response.stream_to_file(speech_file_path)"
      ],
      "metadata": {
        "id": "MmTzI9ZJNqn1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default response format is \"mp3\", but other formats like \"opus\", \"aac\", or \"flac\" are available."
      ],
      "metadata": {
        "id": "993xLlSYPmY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speech_file_path = \"different_language.mp3\"\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"onyx\",\n",
        "    input=\"जिस चीज को आप चाहते हैं, उसमें असफल होना, जिस चीज को आप नहीं चाहते उसमें सफल होने से बेहतर है।\"\n",
        ")\n",
        "\n",
        "response.stream_to_file(speech_file_path)"
      ],
      "metadata": {
        "id": "HPt37T4TOwWH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "31ddsbQcQ_yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Speech to Text\n",
        "\n",
        "Generating transcript in the same language, for file under 25mb, because Whisper API only supports files that are less than 25 MB\n",
        "\n",
        "Supported file format: mp3, mp4, mpeg, mpga, m4a, wav, and webm\n",
        "\n",
        "https://platform.openai.com/docs/guides/speech-to-text/longer-inputs"
      ],
      "metadata": {
        "id": "sSh5B2X3RgcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file= open(\"/content/steve_jobs_speech_generated_hd.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  response_format=\"text\", # Default output format is json,if want in json format, just comment out response format\n",
        "  file=audio_file\n",
        ")\n",
        "transcript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "w1aiOCnERkHQ",
        "outputId": "e0e66c1f-921f-4694-845e-46abdcbcee9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Your time is limited, so don't waste it living someone else's life. Don't be trapped by dogma, which is living with the results of other people's thinking. Don't let the noise of others' opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary. Stay hungry. Stay foolish.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file= open(\"/content/different_language.mp3\", \"rb\")"
      ],
      "metadata": {
        "id": "6eVaxy6ySAIF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = client.audio.translations.create(\n",
        "  model=\"whisper-1\",\n",
        "  response_format = \"text\",\n",
        "  file=audio_file\n",
        ")\n",
        "\n",
        "print(\"Translated Transcript: \", transcript)\n",
        "print(\"\\n\")\n",
        "\n",
        "original_transcript = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  response_format=\"text\",\n",
        "  file=audio_file\n",
        ")\n",
        "\n",
        "print(\"Original Transcript: \", original_transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hnjLP2-RqW0",
        "outputId": "b23ae443-99cd-4db1-fd85-aec0b73f3625"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Transcript:  It is better to be unsuccessful in what you want than to be successful in what you don't want.\n",
            "\n",
            "\n",
            "\n",
            "Original Transcript:  जिस चीज़ को आप चाहते हैं, उसमें असफल होना, जिस चीज़ को आप नहीं चाहते, उसमें सफल होने से बेहतर है।\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub -q"
      ],
      "metadata": {
        "id": "8_MeE4FzVKQg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "song = AudioSegment.from_mp3(\"/content/NLP Roadmap 2024 Step-by-Step Guide Resources.mp3\")\n",
        "\n",
        "# PyDub handles time in milliseconds\n",
        "five_minutes = 1 * 60 * 1000\n",
        "\n",
        "first_5_minutes = song[:five_minutes]\n",
        "\n",
        "first_5_minutes.export(\"split_speech.mp3\", format=\"mp3\")\n",
        "\n",
        "audio_file= open(\"/content/split_speech.mp3\", \"rb\")"
      ],
      "metadata": {
        "id": "ZhwRDGY2SJsL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"You are given video transcript which has spelling mistakes.\n",
        "Here are few terms but not limited that may be misspelled.\n",
        "Terms:\n",
        "Text Pre-Processing, Tokenization, Lemmatization, Spacy, Bag of Words, TF-IDF, Word2Vec, Doc2Vec, Andrew Ng Courses, RNN, LSTM, Pre-trained, Finetuning , NER, Named Entity Recognition,\n",
        "GPT-4, ChatGPT, BERT, Sentence Transformers, Cohere, OpenAI, Llama 2, Illustrated Transformer, LangChain, Pinecone, Chroma DB, Streamlit, FastAPI, AWS EC2, AWS Lambda, PyTorch, Hugging Face, Expert-Vetted\n",
        "MLOps, mlflow, Data Scientist, Freelancing etc.\n",
        "Rewrite transcript in same format correcting spelling mistakes and make sure all terms and keywords listed above anything related to Data Science should be written in title case Eg. Sentence Transformers and not senetence transformers. \"\"\"\n",
        "\n",
        "def transcribe(audio_file):\n",
        "  transcript = client.audio.translations.create(\n",
        "  model=\"whisper-1\",\n",
        "  response_format = \"text\",\n",
        "  file=audio_file\n",
        "  )\n",
        "  return transcript\n",
        "\n",
        "def generate_corrected_transcript(system_prompt, audio_file):\n",
        "    text = transcribe(audio_file)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": text\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "audio_file= open(\"/content/split_speech.mp3\", \"rb\")\n",
        "corrected_text = generate_corrected_transcript(system_prompt, audio_file)\n",
        "corrected_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "WMsuLaBSVG_F",
        "outputId": "2b61f22a-4875-41ec-bf60-974798e88baf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hey hi everyone, welcome back to my channel. So today we are going to discuss the NLP roadmap. So if you are someone who is, let's say, a beginner Data Scientist or someone who wants to pursue a career in Natural Language Processing, today we will discuss how you should approach it, what step-by-step things you should do, what resources you should refer to, and what kind of problems you can solve with that knowledge. That's what we are going to discuss today. I have noted down some of the things that will be helpful for us to discuss. So let me start this thing. I actually earlier shared the NLP roadmap on LinkedIn. I got a really good response, maybe one year back or maybe 8 to 10 months back, something like that. But today, things have changed. There are many libraries and a lot of things have been changed, even the things I use right as my day-to-day job as a Freelancer, those things also have changed. So if you don't know about me, I am Pradeep, I am a full-time Freelance Data Scientist and I primarily do work on the.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7l825iLyVuW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}